{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d5ce77",
   "metadata": {},
   "source": [
    "# This notebook is used to train all models for either deep learning and lgbm for all winner sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32db37",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6941ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from winner_functions import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from lightgbm import plot_importance\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a7b81",
   "metadata": {},
   "source": [
    "This is the list of all set needded to train 7 times both models (lgbm, deep learning) corresponding to month from january to august avoiding april (no race in april)\n",
    ": ['01', '02', '03', '05', '06', '07', '08'] and we have all 470 races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5711ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the month is 01\n",
      "shape of the train set : (5878, 1663)\n",
      "shape of the test set : (83, 1663)\n",
      "We only keep 124 columns in totals\n",
      "shape of the x_train:  (5878, 1618)\n",
      "shape of the y_train:  (5878, 14)\n",
      "shape of the x_train:  (83, 1618)\n",
      "shape of the y_train:  (83, 14)\n"
     ]
    }
   ],
   "source": [
    "#Check some values according to whcih month we select\n",
    "\n",
    "all_month = ['01', '02','03','05', '06','07', '08']\n",
    "\n",
    "month = all_month[0]\n",
    "\n",
    "print(f'the month is {month}')\n",
    "display = True\n",
    "save_model = True\n",
    "X_train, y_train, X_test, y_test, y_train_value, y_test_value, X_test_init = prepare_and_split_data(pd.read_hdf(f'../data/{month}_train_runners.h5','features'),\n",
    "   \n",
    "                                                                          pd.read_hdf(f'../data/{month}_test_runners.h5','features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b92ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "014240a5",
   "metadata": {},
   "source": [
    "## Retrive parameters for LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1dafefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the best paramaters for LGBM from the hyperopt optimisation in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070985d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-27.4</td>\n",
       "      <td>{'boosting': 'gbdt', 'feature_fraction': 0.604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-20.7</td>\n",
       "      <td>{'boosting': 'gbdt', 'feature_fraction': 0.600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.1</td>\n",
       "      <td>{'boosting': 'gbdt', 'feature_fraction': 0.596...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                         Parameters\n",
       "0  -27.4  {'boosting': 'gbdt', 'feature_fraction': 0.604...\n",
       "0  -20.7  {'boosting': 'gbdt', 'feature_fraction': 0.600...\n",
       "0  -15.1  {'boosting': 'gbdt', 'feature_fraction': 0.596..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'boosting': 'gbdt',\n",
       " 'feature_fraction': 0.6,\n",
       " 'learning_rate': 0.03,\n",
       " 'max_depth': 9,\n",
       " 'metric': 'multi_error',\n",
       " 'min_child_samples': 90,\n",
       " 'min_data_in_leaf': 99,\n",
       " 'n_estimators': 300,\n",
       " 'num_class': 14,\n",
       " 'num_leaves': 50,\n",
       " 'objective': 'multiclass',\n",
       " 'reg_alpha': 0.31,\n",
       " 'reg_lambda': 0.68,\n",
       " 'seed': 80,\n",
       " 'subsample': 0.88,\n",
       " 'verbose': -1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = pd.read_csv('results_hyperopt.csv',header = 0, names=[\"Score\",\"Parameters\"]).sort_values(by=\"Score\",ascending = True)\n",
    "parameters.head(3)\n",
    "\n",
    "#convert str to a dict\n",
    "import ast\n",
    "best_params = ast.literal_eval(parameters.iloc[0].Parameters)\n",
    "#best_params\n",
    "\n",
    "#round values to only two after the coma for besr params\n",
    "for k, v in best_params.items():\n",
    "    if isinstance(best_params[k], float):\n",
    "        best_params[k] = round(v, 2)\n",
    "        \n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe9b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecbadcc2",
   "metadata": {},
   "source": [
    "# Do the trainning for all sets and both model deep learning and LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5392f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are trainning for this month: 01\n",
      "shape of the train set : (5878, 1663)\n",
      "shape of the test set : (83, 1663)\n",
      "We only keep 124 columns in totals\n",
      "shape of the x_train:  (5878, 1618)\n",
      "shape of the y_train:  (5878, 14)\n",
      "shape of the x_train:  (83, 1618)\n",
      "shape of the y_train:  (83, 14)\n",
      "trainning deep learning model...\n",
      "Start training..\n",
      "\n",
      "Epoch 1/4\n",
      "118/118 [==============================] - 2s 12ms/step - loss: 2.9754 - precision: 0.1519 - val_loss: 2.4889 - val_precision: 0.0000e+00\n",
      "Epoch 2/4\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 2.1295 - precision: 0.5662 - val_loss: 2.4362 - val_precision: 0.0000e+00\n",
      "Epoch 3/4\n",
      "118/118 [==============================] - 1s 10ms/step - loss: 1.8055 - precision: 0.7540 - val_loss: 2.5287 - val_precision: 0.3333\n",
      "Epoch 4/4\n",
      "118/118 [==============================] - 1s 10ms/step - loss: 1.5613 - precision: 0.8406 - val_loss: 2.5582 - val_precision: 0.1818\n",
      "Done.\n",
      "trainning lgbm...\n"
     ]
    }
   ],
   "source": [
    "# all months we need to test so we train 7 times both models\n",
    "all_month = ['01', '02','03','05', '06','07', '08']\n",
    "\n",
    "\n",
    "for month in all_month : \n",
    "    print(f'We are trainning for this month: {month}')\n",
    "    \n",
    "    #save model indicates if we save the model trainned or not\n",
    "    save_model = False\n",
    "    \n",
    "    #We create all needed sets for both trainning\n",
    "    X_train, y_train, X_test, y_test, y_train_value, y_test_value, X_test_init = prepare_and_split_data(pd.read_hdf(f'../data/{month}_train_runners.h5','features'),\n",
    "                                                                          pd.read_hdf(f'../data/{month}_test_runners.h5','features'))\n",
    "    \n",
    "    \n",
    "    #### DEEP LEARNING\n",
    "    print(\"trainning deep learning model...\")\n",
    "    \n",
    "    #hyperparameters for the deep learning model\n",
    "    num_neutron = 96\n",
    "    batch_size = 50\n",
    "    epoch= 4\n",
    "    \n",
    "    model = train_dl(num_neutron,batch_size,epoch,X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    if save_model:\n",
    "        model.save(f'model/winner_DL_{month}.h5')\n",
    "        \n",
    "        \n",
    "    #### LGBM\n",
    "        \n",
    "    print(\"trainning lgbm...\")\n",
    "    \n",
    "    ## We do this step to avoid multi indexes pandas dataframe\n",
    "    X_train  =  multi_indexes_to_single(X_train)\n",
    "\n",
    "    #classifier1 = LGBMClassifier(seed=80).fit(X_train, y_train_value)\n",
    "    classifier = LGBMClassifier(**best_params).fit(X_train, y_train_value)\n",
    "    \n",
    "    filename = f'model/winner_lgbm_{month}'\n",
    "    #save model\n",
    "    if save_model:\n",
    "        joblib.dump(classifier, filename) \n",
    "        \n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accfbda",
   "metadata": {},
   "source": [
    "# It takes 35 min to train all this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9828164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
